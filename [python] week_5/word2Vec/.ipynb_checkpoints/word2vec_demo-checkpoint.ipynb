{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get paragraph data\n",
    "取得待訓練的文字，為求效率，用長恨歌的某些句子為例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"Automated Detection and Differentiation of Drusen,\n",
    "Exudates, and Cotton-Wool Spots in Digital Color\n",
    "Fundus Photographs for Diabetic Retinopathy Diagnosis\n",
    "Meindert Niemeijer,1,2,3 Bram van Ginneken,1,2,3 Stephen R. Russell,2,4\n",
    "Maria S. A. Suttorp-Schulten,5 and Michael D. Abra`moff 2,3,4\n",
    "PURPOSE. To describe and evaluate a machine learning– based,\n",
    "automated system to detect exudates and cotton-wool spots in\n",
    "digital color fundus photographs and differentiate them from\n",
    "drusen, for early diagnosis of diabetic retinopathy.\n",
    "METHODS. Three hundred retinal images from one eye of 300\n",
    "patients with diabetes were selected from a diabetic retinopathy\n",
    "telediagnosis database (nonmydriatic camera, two-field\n",
    "photography): 100 with previously diagnosed bright lesions\n",
    "and 200 without. A machine learning computer program was\n",
    "developed that can identify and differentiate among drusen,\n",
    "(hard) exudates, and cotton-wool spots. A human expert standard\n",
    "for the 300 images was obtained by consensus annotation\n",
    "by two retinal specialists. Sensitivities and specificities of the\n",
    "annotations on the 300 images by the automated system and a\n",
    "third retinal specialist were determined.\n",
    "RESULTS. The system achieved an area under the receiver operating\n",
    "characteristic (ROC) curve of 0.95 and sensitivity/specificity\n",
    "pairs of 0.95/0.88 for the detection of bright lesions of any type,\n",
    "and 0.95/0.86, 0.70/0.93, and 0.77/0.88 for the detection of exudates,\n",
    "cotton-wool spots, and drusen, respectively. The third retinal\n",
    "specialist achieved pairs of 0.95/0.74 for bright lesions and\n",
    "0.90/0.98, 0.87/0.98, and 0.92/0.79 per lesion type.\n",
    "CONCLUSIONS. A machine learning– based, automated system\n",
    "capable of detecting exudates and cotton-wool spots and differentiating\n",
    "them from drusen in color images obtained in\n",
    "community based diabetic patients has been developed and\n",
    "approaches the performance level of retinal experts. If the\n",
    "machine learning can be improved with additional training\n",
    "data sets, it may be useful for detecting clinically important\n",
    "bright lesions, enhancing early diagnosis, and reducing visual\n",
    "loss in patients with diabetes. (Invest Ophthalmol Vis Sci.\n",
    "2007;48:2260–2267) DOI:10.1167/iovs.06-0996\n",
    "Diabetic retinopathy is the most common cause of blindness\n",
    "in the working population of the United States.1 Early\n",
    "diagnosis and timely treatment have been shown to prevent\n",
    "visual loss and blindness in patients with diabetes.2–4 In patients\n",
    "with recently diagnosed diabetes, a high proportion of\n",
    "normal-appearing fundi are expected, and only 5% to 20% may\n",
    "demonstrate funduscopically visible diabetic retinopathy.5 Digital\n",
    "photography of the retina examined by expert readers has\n",
    "been shown to be sensitive and specific in detecting the early\n",
    "signs of retinopathy.6 Early diabetic retinopathy lesions may be\n",
    "classified as red lesions, such as microaneurysms, hemorrhages,\n",
    "and intraretinal microvascular abnormalities, or bright\n",
    "lesions, such as lipid or lipoprotein exudates, and superficial\n",
    "retinal infarcts (cotton-wool spots).6,7\n",
    "We and others have described machine learning computer\n",
    "systems capable of detecting red lesions and blood vessels in\n",
    "retinal color photographs with high accuracy (Abra`moff MD et al.\n",
    "IOVS 2006;47:ARVO E-Abstract 3635).8–12 Because retinal exudates\n",
    "can represent the only visible sign of early diabetic retinopathy\n",
    "in some patients, computer-based systems that can detect\n",
    "exudates have been proposed.13–17 However, to diagnose the\n",
    "bright lesions associated with diabetic retinopathy—namely, exudates\n",
    "and cotton-wool spots—the lesions must be differentiated\n",
    "from drusen, the bright lesions associated especially with agerelated\n",
    "macular degeneration (AMD), which can have similar\n",
    "appearance,18 as well as from posterior hyaloid reflexes and flash\n",
    "artifacts, which can sometimes mimic bright lesions in appearance.\n",
    "A computer-based system that can detect bright lesions\n",
    "must therefore be capable of differentiating among lesion types,\n",
    "as they have different diagnostic importance and management\n",
    "implications. Extending our previous work on machine learning\n",
    "automated detection of blood vessels and red lesions, we have\n",
    "developed a machine learning algorithm that can detect bright\n",
    "lesions in retinal color photographs and can differentiate among\n",
    "exudates, cotton-wool spots, and drusen.\n",
    "The purpose of this study was to describe and evaluate this\n",
    "machine learning–based computer algorithm to detect exudates\n",
    "and cotton-wool spots in digital color fundus photographs and\n",
    "differentiate them from drusen. The evaluation was performed on\n",
    "a representative sample of images of patients with diabetes drawn\n",
    "from a telediagnosis project in The Netherlands, with 100 color\n",
    "fundus images containing bright lesions and 200 images with no\n",
    "abnormalities. Because the purpose was to compare the machine\n",
    "learning algorithm to that of human experts, a human expert\n",
    "reference standard was created by having three masked retinal\n",
    "specialists annotate the sample photographs.\n",
    "METHODS\n",
    "Subjects\n",
    "A total of 430 retinal images of adequate quality as originally read by an\n",
    "ophthalmologist for clinical reading were selected for this study from the\n",
    "EyeCheck project in The Netherlands.19 Two hundred thirty images were\n",
    "From the 1Image Sciences Institute, University Medical Center\n",
    "Utrecht, Utrecht, The Netherlands; the 2Retina Service, Department of\n",
    "Ophthalmology and Visual Sciences, University of Iowa Hospitals and\n",
    "Clinics, Iowa City, Iowa; the 4Department of Veterans Affairs, Iowa\n",
    "City VA Medical Center, Iowa City, Iowa; the 5Ophthalmology Service,\n",
    "OLVG, Amsterdam, The Netherlands; and the 3Department of Electrical\n",
    "and Computer Engineering, University of Iowa, Iowa City, Iowa.\n",
    "Supported by the Dutch Ministry of Economic Affairs IOP\n",
    "IBVA02016, KNAW Van Walree Fund travel grant (MN); National Eye\n",
    "Institute R01-EY017066, DoD A064-032-0056, Research to Prevent\n",
    "Blindness, the Wellmark Foundation, the U.S. Department of Agriculture;\n",
    "the University of Iowa; and the Netherlands Organization for\n",
    "Health-Related Research (MDA).\n",
    "Submitted for publication August 22, 2006; revised December 29,\n",
    "2006; accepted March 7, 2007.\n",
    "Disclosure: M. Niemeijer (P); B. van Ginneken (P); S.R. Russell,\n",
    "None; M.S.A. Suttorp-Schulten, None; M.D. Abra`moff (P)\n",
    "The publication costs of this article were defrayed in part by page\n",
    "charge payment. This article must therefore be marked “advertisement”\n",
    "in accordance with 18 U.S.C. §1734 solely to indicate this fact.\n",
    "Corresponding author: Michael D. Abra`moff, Retina Service, Department\n",
    "of Ophthalmology and Visual Sciences, University of Iowa\n",
    "Hospitals and Clinics, 200 Hawkins Drive, Iowa City, IA 52242;\n",
    "michael-abramoff@uiowa.edu.\n",
    "Investigative Ophthalmology & Visual Science, May 2007, Vol. 48, No. 5\n",
    "2260 Copyright © Association for Research in Vision and Ophthalmology\n",
    "Downloaded From: http://iovs.arvojournals.org/pdfaccess.ashx?url=/data/journals/iovs/933237/ on 01/05/2018\n",
    "originally read as containing one or more exudates, cotton-wool spots,\n",
    "and/or drusen, and 200 were originally read as not containing any of these\n",
    "bright lesions. One hundred thirty of the images, all originally read as\n",
    "containing bright lesions, were used to train the machine learning algorithm,\n",
    "and 300 images, from 300 subjects, were used to perform diagnostic\n",
    "validation. The EyeCheck project database contains images for over\n",
    "18,000 examinations (over 72,000 images) of patients without previously\n",
    "known diabetic retinopathy.19 The study was performed according to the\n",
    "tenets of the Declaration of Helsinki, and Investigational Review Board\n",
    "approval was obtained. The researchers had access only to the anonymous\n",
    "images and their original diagnoses. Because of the retrospective\n",
    "nature of the study and patient anonymity, informed consent was judged\n",
    "not to be necessary by the Institutional Review Board. The EyeCheck\n",
    "project (http://www.eyecheck.nl) performs early diagnosis of diabetic\n",
    "retinopathy over the Internet in a community-based population using\n",
    "digital cameras in primary care physicians’ offices, and so the images were\n",
    "obtained at multiple sites.\n",
    "Fundus Photography\n",
    "Images were obtained at multiple sites with three different nonmydriatic\n",
    "cameras: the Topcon NW 100, the Topcon NW 200 (Topcon,\n",
    "Tokyo, Japan), and the Canon CR5-45NM (Canon, Tokyo, Japan). The\n",
    "imaging protocol has been published.19 Briefly, digital color photographs\n",
    "were obtained with natural dilation in a dark room, and if\n",
    "natural dilation did not suffice, the pupil was dilated pharmacologically\n",
    "with one drop of tropicamide 0.5% per eye, as per protocol. One\n",
    "disc-centered and one fovea-centered image were obtained for each\n",
    "eye, both at 45° field of view. For the Topcon cameras, spatial resolution\n",
    "was approximately 8 \u0001 8 \u0001m per pixel (2048 \u0001 1536), whereas\n",
    "for the Canon camera, it was approximately 15 \u0001 15 \u0001m (1024 \u0001 768\n",
    "pixels). All cameras had 1-layer CCD RGB sensors, and images were\n",
    "JPEG compressed at the lowest loss compression setting, resulting in\n",
    "image files of approximately 0.15 to 0.5 MB per image.\n",
    "Machine Learning Training Images\n",
    "The machine learning algorithm is a so-called supervised algorithm,\n",
    "and therefore needs a set of annotated lesions to learn how to detect\n",
    "bright lesions and differentiate among them. For this purpose, 130\n",
    "anonymous images originally read as containing bright lesions were\n",
    "selected. All pixels in all these images were segmented by retinal\n",
    "specialist A as to whether they were (part of) an exudate, cotton-wool\n",
    "spot, drusen or background retina. Vessels, disc, and red lesions, if\n",
    "present, were treated as background retina. The images used to create\n",
    "the training set were not included in the test set (described later). The\n",
    "training set contained 1113 exudates (93,067 pixels), 45 cotton-wool\n",
    "spots (33,959 pixels), and 2030 drusen (287,186 pixels).\n",
    "Image Data Set for Testing Performance\n",
    "Three hundred anonymous images were selected as the testing set. One\n",
    "hundred images were selected at random from all images that were\n",
    "originally read clinically as containing one or more bright lesions, and 200\n",
    "images were selected from all images originally read as containing no\n",
    "lesions (not containing any exudates, cotton-wool spot, or drusen). Three\n",
    "masked retinal specialists (designated A, B, and C) performed annotation\n",
    "on all images in random order indicating whether one or more exudates,\n",
    "cotton-wool spots or drusen or any combination thereof was present. A\n",
    "consensus annotation was then obtained, using a teleconference discussion\n",
    "format, by asking two of the retinal specialists (A, B) to reach\n",
    "consensus on all images where their independent annotations had differed.\n",
    "The consensus annotation was used as the reference standard, and\n",
    "contained 105 images with bright lesions and 195 without. In other\n",
    "words, some images originally thought to be without bright lesions did\n",
    "contain one or more bright lesions according to the consensus reference\n",
    "standard and vice versa. There were 42 images with exudates, 30 with\n",
    "cotton-wool spots, and 52 with drusen in this test set. Some images also\n",
    "contained red lesions (microaneurysms, hemorrhages, microvascular abnormalities,\n",
    "or neovascularizations), and the distribution of the presence\n",
    "of lesions is given in Table 1.\n",
    "Machine Learning Algorithm\n",
    "The machine learning algorithm is based on our earlier work using\n",
    "retinal pixel and lesion classification.8–10 To perform detection and\n",
    "differentiation of bright lesions, if any, in a previously unseen image,\n",
    "the following steps were performed:\n",
    "1. Each pixel was classified, resulting in a so-called lesion probability\n",
    "map that indicates the probability that a pixel is part of a\n",
    "bright lesion.\n",
    "2. Pixels with high probability were grouped into probable lesion\n",
    "pixel clusters.\n",
    "3. Based on cluster characteristics each probable lesion pixel cluster\n",
    "was assigned a probability indicating the likelihood that the\n",
    "pixel cluster was a true bright lesion.\n",
    "4. Each bright lesion cluster likely to be a bright lesion was\n",
    "classified as exudate, cotton-wool spot or drusen.\n",
    "Figure 1 illustrates these steps. The system performs the classification\n",
    "steps (1, 3, and 4) by using a statistical classifier that, given a training\n",
    "set of labeled examples, can differentiate among different types of\n",
    "pixels or clusters based on so-called features or numerical characteristics,\n",
    "such as pixel color and cluster area. The features used depend on\n",
    "the type of objects that are to be classified. For each classification step,\n",
    "several statistical classifiers were tested on the training set and the one\n",
    "demonstrating the best performance was used on the test set. A\n",
    "k-nearest neighbor classifier was selected for steps 1 and 3 and a linear\n",
    "discriminant classifier for the third classification step.16 When presented\n",
    "with an unseen image in the test set, the automated algorithm\n",
    "gave two outputs: whether bright lesions were present or not, and\n",
    "which class each lesion was: exudate, cotton-wool spot, or drusen. A\n",
    "more extensive description of the algorithm is given in the Appendix.\n",
    "Outcome Parameters and Data Analysis\n",
    "The machine learning algorithm annotated all images in the test set\n",
    "repeatedly, while varying the threshold for normal/abnormal cutoff\n",
    "(steps 1 and 3). Sensitivity, specificity, and \u0002 of the annotation compared\n",
    "with the consensus standard was calculated at each threshold\n",
    "setting. Sensitivity, specificity, and \u0002 of retinal specialist C compared\n",
    "with the consensus standard were also determined. For the machine\n",
    "learning algorithm, these sensitivity–specificity pairs can be used to\n",
    "create receiver operator characteristic (ROC) curves for all bright\n",
    "lesions, and for the differentiation of exudates, cotton-wool spots, and\n",
    "drusen. The ROC curve shows the sensitivity and specificity at various\n",
    "thresholds, and the system can be set for a specific sensitivity/specificity\n",
    "by selecting the corresponding threshold. For a screening system,\n",
    "sensitivity is more important than specificity, so a threshold could be\n",
    "chosen that maximizes sensitivity while still maintaining enough specificity.\n",
    "Because human experts cannot (consciously) adjust their lesiondetection\n",
    "threshold, only a single sensitivity–specificity pair was obtained\n",
    "for each human grader and plotted in the ROC curve as a point\n",
    "(Fig. 2). The area under the ROC curve is regarded as the most accurate\n",
    "and comprehensive measure of system performance: an area of 1.0 has\n",
    "sensitivity \u0002 specificity \u0002 1 and represents perfect detection, whereas\n",
    "an area of 0.5 is the performance of a system that essentially performs\n",
    "a coin toss. The number of images in which the original annotations of\n",
    "all three retinal specialists (designated A, B, and C) and the machine\n",
    "learning algorithm agreed, were also determined for all bright lesions\n",
    "as a group and for the three classes of lesions individually.\n",
    "TABLE 1. Distribution of Presence of Red and Bright Lesions in the\n",
    "Test Images\n",
    "Red \u0001 Red \u0002 Total\n",
    "Bright\u0003 34 71 105\n",
    "Bright\u0004 4 191 195\n",
    "Total 38 262 300\n",
    "IOVS, May 2007, Vol. 48, No. 5 Automated Differentiation of Drusen, Exudates, and Cotton-Wool Spots 2261\n",
    "Downloaded From: http://iovs.arvojournals.org/pdfaccess.ashx?url=/data/journals/iovs/933237/ on 01/05/2018\n",
    "RESULTS\n",
    "Table 2 shows sensitivity, specificity, and \u0002 of the machine\n",
    "learning algorithm and retinal specialist C, compared with the\n",
    "consensus standard.\n",
    "Figure 2 shows the ROC curves for the system and the ROC\n",
    "points for retinal specialist C, for both overall bright lesion detection\n",
    "and bright lesion differentiation per image. The area under\n",
    "the curve of the automated system for the detection of bright\n",
    "lesions was 0.95, and for the detection of exudates, cotton-wool\n",
    "spots, and drusen it was 0.94, 0.85, and 0.88, respectively.\n",
    "The automated system achieved sensitivity/specificity of\n",
    "0.95/0.88 for the detection all bright lesions, and 0.95/0.86,\n",
    "0.70/0.93, and 0.77/0.88 for the detection of exudates, cottonwool\n",
    "spots, and drusen, respectively. The third retinal specialist\n",
    "achieved 0.95/0.74 for bright lesions, and 0.90/0.98, 0.87/\n",
    "0.98, and 0.92/0.79 for the detection of exudates, cotton-wool\n",
    "spots, and drusen, respectively.\n",
    "In total, 1739 bright lesions were detected at this optimal\n",
    "threshold setting. Of these 1739 lesions, 1513 lesions were\n",
    "classified correctly, and 226 were inaccurate classifications. Of\n",
    "the latter, 124 drusen were misclassified as exudates, 49 exudates\n",
    "were misclassified as drusen, 5 drusen were misclassified\n",
    "as cotton-wools spots, 2 exudates were misclassified as cottonwool\n",
    "spots, and there were 45 other confused classifications,\n",
    "either misclassifications or nonlesions. Because the consensus\n",
    "standard was determined by two independent retinal specialists,\n",
    "it was useful to determine the \u0002 of their (independent)\n",
    "annotations before the consensus process, and these were\n",
    "0.80, 0.65, 0.73, and 0.65, respectively.\n",
    "In 225 of 300 images, the consensus standard, the automated\n",
    "system and retinal specialist C were all in full agreement\n",
    "on the presence of bright lesions. In 167 of 300 cases, the\n",
    "consensus standard, the automated system, and retinal specialist\n",
    "C were in full agreement on the type(s) of bright lesion.\n",
    "Examples are shown in Figure 3A and 3B. Two examples of\n",
    "cases where human experts did not agree among themselves\n",
    "and the automated system also did not agree with the human\n",
    "experts are shown in Figures 3C and 3D.\n",
    "DISCUSSION\n",
    "Our results demonstrate that a machine learning algorithm, as\n",
    "described herein, is capable of detecting exudates, cottonwool\n",
    "spots, and drusen and differentiating among them on\n",
    "color images of the retina obtained in a community-based\n",
    "population of patients with diabetes. The area under the ROC\n",
    "curve of 0.95 shows that this proof-of-concept system has\n",
    "sensitivity and specificity approaching that of retinal experts.\n",
    "Differentiating among the three types of bright lesions from\n",
    "color photographs can be challenging, as illustrated by Figures\n",
    "3A–D. The lesions in these images are subtle, and correct\n",
    "differentiation may be improved with knowledge of patient\n",
    "age, consideration of contextual lesions, and the size of lesion\n",
    "classes. Despite the complexity of this task, in 1513 (87%) of\n",
    "1739 cases, the automated system and the three retinal specialists\n",
    "agreed on the presence and type of lesion. As might be\n",
    "FIGURE 1. Machine learning algorithm\n",
    "steps performed to detect and\n",
    "differentiate bright lesions. From left\n",
    "to right columns: exudates, cottonwool\n",
    "spots, and drusen. From top to\n",
    "bottom: first row shows the relevant\n",
    "region in the retinal color image (all\n",
    "at the same scale), second row: posterior\n",
    "probability map after the first\n",
    "classification step; third row: pixel\n",
    "clusters that are probable bright lesions\n",
    "(potential lesions); bottom\n",
    "row: objects that the system classified\n",
    "as true bright lesions overlaid on\n",
    "the original image.\n",
    "2262 Niemeijer et al. IOVS, May 2007, Vol. 48, No. 5\n",
    "Downloaded From: http://iovs.arvojournals.org/pdfaccess.ashx?url=/data/journals/iovs/933237/ on 01/05/2018\n",
    "expected, drusen and exudates were easily confused because\n",
    "they are often similar in size, whereas cotton-wool spots are\n",
    "less often confused with the other two types of lesions.\n",
    "The existing literature has focused almost exclusively on\n",
    "the automatic detection of exudates, only a single study included\n",
    "the detection of cotton-wool spots, and no studies took\n",
    "account of drusen in this context.13–15,17,18,20 Our results indicate\n",
    "that of all three bright lesion types, exudates present the easiest\n",
    "lesion to detect for both automated system and retinal specialist\n",
    "C. The capacity of our system algorithm to detect and differentiate\n",
    "all three types of lesions distinguishes it from prior studies.\n",
    "Despite the encouraging performance achieved by the\n",
    "present system, several major issues remain. One disadvantage\n",
    "of this study is its simple application. We compare the machine\n",
    "learning system and human experts’ performance on digital\n",
    "fundus photographs obtained in a telediagnosis setting with\n",
    "nonmydriatic cameras. The accepted standard for detection of\n",
    "diabetic retinopathy is seven-field stereo fundus photography\n",
    "by certified photographers and read by certified readers.21\n",
    "However, the reference standard used here is the consensus\n",
    "reading of the photographs by retinal specialists. This study,\n",
    "and the trained algorithm, may be biased, and some bright\n",
    "lesions may have been missed by both human experts and the\n",
    "automated system because of the limitations of digital two-field\n",
    "nonstereo photography.6 Because we set out to compare the\n",
    "performance of the system to human experts on the same\n",
    "photographs, our results are only valid in that context. To\n",
    "achieve a more comprehensive evaluation of this or a similar\n",
    "system, a comparison of the machine learning algorithm on\n",
    "nonmydriatic nonstereo images, to seven-field nonmydriatic\n",
    "images evaluated by human experts, would be necessary.\n",
    "A second limiting factor that might limit optimal performance\n",
    "of the machine learning algorithm could be a constraint of the\n",
    "quality of the annotations of the training images. In other words,\n",
    "the better this training set, the better the theoretical performance\n",
    "of the algorithm. Improving the quality of the training data using\n",
    "multiple experienced clinicians and a larger number of training\n",
    "pixels, may improve system performance and also lessen the\n",
    "FIGURE 2. ROC curves of the automatic\n",
    "system for the different detection\n",
    "tasks. Sensitivity/specificity pairs\n",
    "of retinal specialist C are also plotted\n",
    "as points in the graph.\n",
    "TABLE 2. Sensitivity, Specificity, and \u0002 of the Machine Learning Algorithm and Retinal Specialist C Compared with the Reference Standard\n",
    "Sensitivity Specificity \u0003\n",
    "Machine Learning\n",
    "Algorithm\n",
    "Retinal\n",
    "Specialist C\n",
    "Machine Learning\n",
    "Algorithm\n",
    "Retinal\n",
    "Specialist C\n",
    "Machine Learning\n",
    "Algorithm\n",
    "Retinal\n",
    "Specialist C\n",
    "Bright lesions 0.95 0.95 0.88 0.74 0.80 0.63\n",
    "Exudates 0.95 0.90 0.86 0.98 0.61 0.88\n",
    "Cotton-wool spots 0.70 0.87 0.93 0.98 0.57 0.82\n",
    "Drusen 0.77 0.92 0.88 0.79 0.56 0.52\n",
    "IOVS, May 2007, Vol. 48, No. 5 Automated Differentiation of Drusen, Exudates, and Cotton-Wool Spots 2263\n",
    "Downloaded From: http://iovs.arvojournals.org/pdfaccess.ashx?url=/data/journals/iovs/933237/ on 01/05/2018\n",
    "problem of clinician interobserver variability as evidenced in Figures\n",
    "3C and 3D.\n",
    "Third, both human readers and algorithms have difficulty detecting\n",
    "retinal thickening, especially in the absence of context\n",
    "lesions such as exudates, beading, or hemorrhages. Judging retinal\n",
    "thickening is especially difficult when using nonstereo fundus\n",
    "photography for early diagnosis.2,6,21 Retinal thickening without\n",
    "context lesions, if present, will be missed by the algorithm. This\n",
    "FIGURE 3. (A) Sample image about\n",
    "which experts and the automated\n",
    "system agreed on the presence of\n",
    "exudates and cotton-wool spots. As\n",
    "identified by the automated system;\n",
    "red arrows: exudates; green arrow:\n",
    "cotton-wool spot. (B) Sample image\n",
    "about which experts and the automated\n",
    "system agreed on the presence\n",
    "of drusen. As identified by the\n",
    "automated system, the blue arrows\n",
    "denote drusen. (C) Sample image\n",
    "about which experts and automated\n",
    "system did not agree on the presence\n",
    "of drusen or exudates. As identified\n",
    "by the automated system, the blue\n",
    "arrows denote drusen (retinal specialist\n",
    "A and the automated system)\n",
    "or exudates (retinal specialists B and\n",
    "C), and the red arrows denote exudates\n",
    "(retinal specialists B and C and\n",
    "the automated system) or drusen\n",
    "(retinal specialist A). (D) Sample image\n",
    "about which experts and automated\n",
    "system did not agree on the\n",
    "presence of druse, exudate, or cotton-\n",
    "wool spot. As identified by the\n",
    "automated system, the blue arrow\n",
    "denotes a druse (automated system),\n",
    "exudate (retinal specialists B and C),\n",
    "or no abnormality (retinal specialist\n",
    "A); the green arrow denotes a cotton-\n",
    "wool spot (retinal specialist C\n",
    "and the automated system), exudate\n",
    "(retinal specialist B), or no abnormality\n",
    "(retinal specialist A).\n",
    "2264 Niemeijer et al. IOVS, May 2007, Vol. 48, No. 5\n",
    "Downloaded From: http://iovs.arvojournals.org/pdfaccess.ashx?url=/data/journals/iovs/933237/ on 01/05/2018\n",
    "is a downside of nonstereo fundus photography, whether read by\n",
    "human experts or an algorithm, though the relative frequency of\n",
    "retinal thickening without context signs may be low.22,23\n",
    "Fourth, the system has been tested on a small number of\n",
    "patients. If tested on a larger prospective data set, performance\n",
    "may not be comparable to these results.\n",
    "The ROCs in Figure 2 are interesting because they suggest that\n",
    "professional experience or training differences may affect the\n",
    "performance of human experts. Retinal specialist C is an expert\n",
    "on AMD research and drug trials, in addition to being an expert in\n",
    "diabetic retinopathy, while retinal specialists A and B are primarily\n",
    "diabetic retinopathy specialists. As Table 2 depicts, the performance\n",
    "of C compared with the consensus standard on cottonwool\n",
    "spots and exudates is comparable, but C is much more\n",
    "sensitive to drusen: one possible explanation is C’s heightened\n",
    "awareness of subtle AMD lesions.\n",
    "An important question that cannot be answered by a preliminary\n",
    "study such as the present one is how the current algorithm, capable\n",
    "FIGURE 3. (Continued)\n",
    "IOVS, May 2007, Vol. 48, No. 5 Automated Differentiation of Drusen, Exudates, and Cotton-Wool Spots 2265\n",
    "Downloaded From: http://iovs.arvojournals.org/pdfaccess.ashx?url=/data/journals/iovs/933237/ on 01/05/2018\n",
    "of detecting and differentiating exudates, cotton-wool spots and\n",
    "drusen, might fit into a complete system for diabetic retinopathy\n",
    "classification and healthcare delivery. We envision several different\n",
    "approaches, one of which would be a system for early detection of\n",
    "diabetic retinopathy in patients with diabetes who currently are not\n",
    "receiving the recommended regular dilated eye examinations. Such a\n",
    "system may require the following subcomponents, many of which\n",
    "we and others have presented previously:\n",
    "1. Quality assurance: an algorithm capable of detecting\n",
    "images that are not adequate, such as flash artifacts,\n",
    "blinking, blur, and cataract.24\n",
    "2. Vessel segmentation: an algorithm capable of segmenting\n",
    "the retinal blood vessels, even when disease is\n",
    "present.8,9,25\n",
    "3. Segmentation of optic disc and possibly fovea: an algorithm\n",
    "capable of localizing and segmenting these substructures.\n",
    "26–29\n",
    "4. Microaneurysm, retinal hemorrhage, neovascularization,\n",
    "and other retinal microvascular abnormalities: an algorithm\n",
    "for detecting these red lesions.10\n",
    "5. Exudate and cotton-wool spot detection and differentiation\n",
    "from non-DR bright lesions: the algorithm presented\n",
    "herein.\n",
    "6. Combination of the outputs of these subcomponents\n",
    "over multiple images of a single patient into a simple\n",
    "diabetic retinopathy probability statistic.\n",
    "In conclusion, we have developed and tested a machine learning\n",
    "system capable of detecting exudates, cotton-wool spots, and\n",
    "drusen, and differentiating among these, on color images of the\n",
    "retina obtained in a population of patients with diabetes. The\n",
    "performance of this proof-of-concept system has sensitivity and\n",
    "specificity that approaches retinal experts. If such a system can be\n",
    "improved by better quality training data and tested on larger data\n",
    "sets, it has the potential to help prevent visual loss and blindness\n",
    "in patients with diabetes.\n",
    "APPENDIX: MACHINE LEARNING SYSTEM:\n",
    "FEATURE CLASSIFICATION\n",
    "Probability that a Pixel Is Part of a Bright Lesion\n",
    "To determine the probability for all pixels in an image (in the test set)\n",
    "to be part of a bright lesion, the green channel of the RGB camera\n",
    "image is convolved with a set of 14 digital filters. These filters are\n",
    "based on Gaussian derivatives and are invariant to rotation and translation\n",
    "of the image. The specific image filters used were selected\n",
    "from a larger set of second-order irreducible invariants,30 by using the\n",
    "training images and a feature selection algorithm. If a bright lesion is\n",
    "present, the combination of filter responses for pixels in or close to\n",
    "that bright lesion will be different from the filter responses for\n",
    "nonlesion pixels. The classifier used to classify the pixels on the basis\n",
    "of the filter responses, was a k-nearest neighbor (kNN) classifier.16\n",
    "Such a classifier is capable of assigning probabilities to pixels in an\n",
    "image based on the combination of filter responses and can generate\n",
    "a lesion probability map (example: second row of Fig. 1) that indicates\n",
    "the probability that each pixel is part of a bright lesion. The\n",
    "kNN classifier is a machine learning algorithm and is trained by\n",
    "offering it a set of training pixels from the training image set where\n",
    "the classification has been established (bright lesion or nonbright\n",
    "lesion).\n",
    "Potential Bright Lesion Pixel Clusters\n",
    "By setting the threshold at 60% (pixels with a probability higher\n",
    "than 60% are considered part of a bright lesion and retained) by\n",
    "grouping connected pixels above this threshold, a set of bright\n",
    "lesion pixel clusters is obtained (example: third row of Fig. 3).\n",
    "Because their output is required for further processing, algorithms\n",
    "that perform red lesion classification, optic disc segmentation,\n",
    "and vessel segmentation were applied to the images as we have\n",
    "TABLE A1. Overview of the Features Used to Determine Whether a Potential Lesion Is a True Bright Lesion or a Spurious Determination\n",
    "Feature Number Description\n",
    "1 Area in pixels of potential lesion.\n",
    "2 Length of the perimeter in pixels of the potential lesion.\n",
    "3 Compactness of the potential lesion.\n",
    "4,5 Length and width in pixels of the potential lesion.\n",
    "6 Mean gradient value at scale of two pixels at the potential lesion border.\n",
    "7/8 Mean/standard deviation of all green channel pixels within the potential lesion after shade correction (i.e., a 48-pixel\n",
    "Gaussian blurred version of the image is subtracted from the image itself).\n",
    "9/10 Mean/standard deviation of all green channel pixels in a square region outside the potential lesion after shade\n",
    "correction. Square region is 50 \u0001 50 pixels unless the potential lesion is larger than 25 pixels wide or high, when the\n",
    "width or height or both are calculated according to the following formula: dist \u0002 (dist/25.0f) \u0001 50\n",
    "11/12/13 Mean CIE (International Commission on Illumination)–LUV intensities of all pixels within the potential lesion.\n",
    "14/15/16 Standard deviation of CIE (International Commission on Illumination)–LUV intensities of all pixels within the potential\n",
    "lesion.\n",
    "17/18/19 Mean CIE (International Commission on Illumination)–LUV intensities of all pixels in the square region outside the\n",
    "potential lesion (see formula in 9/10).\n",
    "20/21/22 Standard deviation of CIE (International Commission on Illumination)–LUV intensities of all pixels in the square region\n",
    "outside the potential lesion (see formula in 9/10).\n",
    "23 Local pixel contrast in the green channel, by subtracting the average pixel intensity within the potential lesion from the\n",
    "average pixel value in a three pixel wide border around the potential lesion. The border is obtained by dilating the\n",
    "potential lesion three times with a single pixel.\n",
    "24 Local pixel variance contrast in the green channel, similar to 23 but the variance is used instead of the average.\n",
    "25/26 Same as 7/8 but using a locally normalized image.\n",
    "27/28 Same as 9/10 but using a locally normalized image.\n",
    "29/30 Same as 9/10 but pixels of other potential lesions are excluded from the outside area pixel means and standard\n",
    "deviations.\n",
    "31/32 Same as 9/10, but pixels of vessels are excluded from the outside area pixel means and standard deviations\n",
    "33/80 Mean/standard deviation of filter outputs. Gaussian filter bank: I, Ix, Iy, Ixy, Ixx, Iyy at scales 1,2,4,8 pixels.\n",
    "81 Mean vessel probability at the potential lesion boundary, obtained from vessel probability map.\n",
    "82 Standard deviation of vessel probability at the potential lesion boundary, obtained as before.\n",
    "83 Distance in pixels to the closest red lesion.\n",
    "2266 Niemeijer et al. IOVS, May 2007, Vol. 48, No. 5\n",
    "Downloaded From: http://iovs.arvojournals.org/pdfaccess.ashx?url=/data/journals/iovs/933237/ on 01/05/2018\n",
    "previously described.8–10,26 That part of a bright lesion that overlaps\n",
    "with the optic disc is removed at this step, using the segmented\n",
    "optic disc. From here on, such a bright lesion pixel\n",
    "cluster will be termed potential lesion.\n",
    "Bright Lesion Detection\n",
    "The potential lesions include potential spurious responses, most\n",
    "of which occur along the major vessels and some of which are\n",
    "from posterior hyaloid reflexes. A second kNN classifier was\n",
    "trained by using a set of sample potential lesions extracted from\n",
    "the training set to suppress spurious bright lesion clusters (Table\n",
    "A1 for the features used). The contrast features measure the\n",
    "contrast of the cluster in multiple image RGB color planes, and\n",
    "other features provide information about the size, shape, and\n",
    "contrast of a potential lesion; its proximity to the closest vessel;\n",
    "and proximity to the closest red lesion, as potential lesions close\n",
    "to a red lesion are more likely to be true bright lesions. Each\n",
    "potential lesion is thereby assigned a probability indicating the\n",
    "likelihood that it is a true bright lesion. The probability that the\n",
    "image contains any type of bright lesion is now given by the\n",
    "maximum probability assigned to any of the potential lesions in\n",
    "the image. For the final classification step, all potential lesions\n",
    "with a probability below 70% were discarded. The value for this\n",
    "threshold was determined on the training set, and the results\n",
    "were not very sensitive to small variations in this threshold (see\n",
    "the bottom row of Fig. 3).\n",
    "Bright Lesion Classification\n",
    "A third classifier was trained using the bright lesion types from\n",
    "the training set. The features described in Table A1, and in\n",
    "addition, the following features were used:\n",
    "1. The number of red lesions in the image.\n",
    "2. The number of detected bright lesions from the previous\n",
    "step.\n",
    "3. The probability for the cluster.\n",
    "A linear discriminant analysis classifier labeled all found lesions\n",
    "in the test set as to whether they were exudates, cotton-wool,\n",
    "or drusen.16\n",
    "References\n",
    "1. Klonoff DC, Schwartz DM. An economic analysis of interventions\n",
    "for diabetes. Diabetes Care. 2000;23:390–404.\n",
    "2. Kinyoun J, Barton F, Fisher M, Hubbard L, Aiello L, Ferris F III. Detection\n",
    "of diabetic macular edema: ophthalmoscopy versus photography—Early\n",
    "Treatment Diabetic Retinopathy Study Report Number 5. The ETDRS\n",
    "Research Group. Ophthalmology. 1989;96:746–750.\n",
    "3. Early photocoagulation for diabetic retinopathy. ETDRS report\n",
    "number 9. Early Treatment Diabetic Retinopathy Study Research\n",
    "Group. Ophthalmology. 1991;98:766–785.\n",
    "4. Bresnick GH, Mukamel DB, Dickinson JC, Cole DR. A screening approach\n",
    "to the surveillance of patients with diabetes for the presence of\n",
    "vision-threatening retinopathy. Ophthalmology. 2000;107:19–24.\n",
    "5. Wilson C, Horton M, Cavallerano J, Aiello LM. Addition of primary\n",
    "care-based retinal imaging technology to an existing eye care professional\n",
    "referral program increased the rate of surveillance and treatment\n",
    "of diabetic retinopathy. Diabetes Care. 2005;28:318–322.\n",
    "6. Lin DY, Blumenkranz MS, Brothers RJ, Grosvenor DM. The sensitivity\n",
    "and specificity of single-field nonmydriatic monochromatic\n",
    "digital fundus photography with remote image interpretation for\n",
    "diabetic retinopathy screening: a comparison with ophthalmoscopy\n",
    "and standardized mydriatic color photography. Am J Ophthalmol.\n",
    "2002;134:204–213.\n",
    "7. Olson JA, Strachan FM, Hipwell JH, et al. A comparative evaluation of\n",
    "digital imaging, retinal photography and optometrist examination in\n",
    "screening for diabetic retinopathy. Diabet Med. 2003;20:528–534.\n",
    "8. Niemeijer M, Staal JS, van Ginneken B, Loog M, Abra`moff MD.\n",
    "Comparative study of retinal vessel segmentation on a new publicly\n",
    "available database. Proc SPIE 2004;5370–5379.\n",
    "9. Staal JS, Abra`moff MD, Niemeijer M, Viergever MA, van Ginneken,\n",
    "B. Ridge based vessel segmentation in color images of the retina.\n",
    "IEEE Trans Med Imaging. 2004;23:501–509.\n",
    "10. Niemeijer M, vanGinneken B, Staal J, Suttorp-Schulten MS,\n",
    "Abra`moff MD. Automatic detection of red lesions in digital color\n",
    "fundus photographs. IEEE Trans Med Imaging. 2005;24:584–592.\n",
    "11. Larsen M, Godt J, Larsen N, et al. Automated detection of fundus\n",
    "photographic red lesions in diabetic retinopathy. Invest Ophthalmol\n",
    "Vis Sci. 2003;44:761–766.\n",
    "12. Spencer T, Olson JA, McHardy KC, Sharp PF, Forrester JV. An\n",
    "image-processing strategy for the segmentation and quantification\n",
    "of microaneurysms in fluorescein angiograms of the ocular fundus.\n",
    "Comput Biomed Res. 1996;29:284–302.\n",
    "13. Gardner GG, Keating D, Williamson TH, Elliott AT. Automatic\n",
    "detection of diabetic retinopathy using an artificial neural\n",
    "network: a screening tool [see comments]. Br J Ophthalmol.\n",
    "1996;80:940–944.\n",
    "14. Sinthanayothin C, Boyce JF, Williamson TH, et al. Automated\n",
    "detection of diabetic retinopathy on digital fundus images. Diabet\n",
    "Med. 2002;19:105–112.\n",
    "15. Osareh A, Mirmehdi M, Thomas B, Markham R. Automated identification\n",
    "of diabetic retinal exudates in digital colour images. Br J\n",
    "Ophthalmol. 2003;87:1220–1223.\n",
    "16. Duda RA, Hart PE, Stork DG. Pattern Classification. New York:\n",
    "Wiley-Interscience; 2001.\n",
    "17. Walter T, Klein JC, Massin P, Erginay A. A contribution of image\n",
    "processing to the diagnosis of diabetic retinopathy—detection of\n",
    "exudates in color fundus images of the human retina. IEEE Trans\n",
    "Med Imaging. 2002;21:1236–1243.\n",
    "18. Usher D, Dumskyj M, Himaga M, Williamson TH, Nussey S, Boyce\n",
    "J. Automated detection of diabetic retinopathy in digital retinal\n",
    "images: a tool for diabetic retinopathy screening. Diabet Med.\n",
    "2004;21:84 –90.\n",
    "19. Abra`moff MD, Suttorp-Schulten MS. Web-based screening for diabetic\n",
    "retinopathy in a primary care population: the EyeCheck\n",
    "project. Telemed J E Health. 2005;11:668–674.\n",
    "20. Lee SC, Lee ET, Kingsley RM, et al. Comparison of diagnosis of\n",
    "early retinal lesions of diabetic retinopathy between a computer\n",
    "system and human experts. Arch Ophthalmol. 2001;119:509–515.\n",
    "21. Early Treatment Diabetic Retinopathy Study Research Group.\n",
    "Grading diabetic retinopathy from stereoscopic color fundus photographs—\n",
    "an extension of the modified Airlie House classification.\n",
    "ETDRS report number 10. Ophthalmology. 1991;98:786–806.\n",
    "22. Schiffman RM, Jacobsen G, Nussbaum JJ, et al. Comparison of a\n",
    "digital retinal imaging system and seven-field stereo color fundus\n",
    "photography to detect diabetic retinopathy in the primary care\n",
    "environment. Ophthalmic Surg Lasers Imaging. 2005;36:46 –56.\n",
    "23. Welty CJ, Agarwal A, Merin LM, Chomsky A. Monoscopic versus\n",
    "stereoscopic photography in screening for clinically significant macular\n",
    "edema. Ophthalmic Surg Lasers Imaging. 2006;37:524–526.\n",
    "24. Niemeijer M, van Ginneken B, Abra`moff MD. Image structure\n",
    "clustering for image quality verification of color retina images in\n",
    "diabetic retinopathy screening. Med Image Anal J.\n",
    "25. Hoover A, Kouznetsova V, Goldbaum M. Locating blood vessels in\n",
    "retinal images by piecewise threshold probing of a matched filter\n",
    "response. IEEE Trans Med Imaging. 2000;19:203–210.\n",
    "26. Abra`moff MD, Niemeijer M. Automatic Detection of the Optic Disc\n",
    "Location in Retinal Images Using Optic Disc Location Regression.\n",
    "Presented at the 28th Annual International Conference of\n",
    "IEEE EMBS (Engineering in Medicine and Biology Society). New\n",
    "York: IEEE: 2006;4432–4435.\n",
    "27. Niemeijer M, Abra`moff MD, van Ginneken B. Segmentation of the\n",
    "optic disc, macula and vascular arch in fundus photographs. IEEE\n",
    "Trans Med Imaging. 2007;26:116–127.\n",
    "28. Foracchia M, Grisan E, Ruggeri A. Detection of optic disc in retinal\n",
    "images by means of a geometrical model of vessel structure. IEEE\n",
    "Trans Med Imaging. 2004;23:1189–1195.\n",
    "29. Abra`moff MD, Alward WL, Greenlee EC, et al. Automated segmentation\n",
    "of the optic nerve head from stereo color photographs.\n",
    "Invest Ophthalmol Vis Sci. 2007;48:1665–1673.\n",
    "30. ter Haar Romeny BM. Front End Vision and Multi-scale Image\n",
    "Analysis. Dordrecht, The Netherlands: Kluwer Academic\n",
    "Publishers; 2003.\n",
    "IOVS, May 2007, Vol. 48, No. 5 Automated Differentiation of Drusen, Exudates, and Cotton-Wool Spots 2267\n",
    "Downloaded From: http://iovs.arvojournals.org/pdfaccess.ashx?url=/data/journals/iovs/933237/ on 01/05/2018\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 斷句\n",
    "用jieba 的方式，把paragraph中的語句斷句，並輸出到 test.txt 當中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "output = open('test.txt', 'w',encoding=\"utf-8\")\n",
    "paragraph=paragraph.strip('\\n')\n",
    "words = jieba.cut(paragraph)\n",
    "for ele in words:\n",
    "    output.write(ele + ' ')\n",
    "    output.write('\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim.models import word2vec\n",
    "def main():\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    sentences = word2vec.LineSentence(\"test.txt\")\n",
    "    print(sentences)\n",
    "    model = word2vec.Word2Vec(sentences, size=250)\n",
    "\n",
    "    #保存模型，供日後使用\n",
    "    model.save(\"word2vec.model\")\n",
    "\n",
    "    #模型讀取方式\n",
    "    model = word2vec.Word2Vec.load(\"your_model_name\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Photography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 待解決問題\n",
    "\n",
    "1.中文字很不容易讀\n",
    "2.建置model過程冗長\n",
    "\n",
    "# 課後練習\n",
    "\n",
    "分析歷屆學測考古題"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
